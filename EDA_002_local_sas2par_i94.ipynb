{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Objective: convert the i94 monthly sas7bdata files into parquet files.\n",
    "\n",
    "Approach: during development we do this locally (within Udacity virtual environment) to avoid AWS compute  compute cost. Only when we are ready, we may migrate this process to AWS completely.\n",
    "\n",
    "This notebook is designed to be run on Udacity virtual environment only.\n",
    "\n",
    "Read the 12 monthly SAS7BDAT i94 files from 2016 into a Spark DataFrame. Write the Spark DataFrame into the parquet files in 3 ways:\n",
    "\n",
    "1. no partitioning  <-- turns out to be most useful for initial EDA.\n",
    "2. partiion by month  <-- for experiment only. Just to prove we can do it.\n",
    "3. partition by year and month. <-- for experiment only. Just to prove we can do it.\n",
    "\n",
    "Lesson learnt: whenever we use a Spark DataFrame column as a partition column, we lose that column in the actual dataset. e.g. if we use i94yr and i94mon as partition keys, we lose these two columns in the actual dataset. Partition keys may be useful for filtering (via Spark SQL WHERE), but may not be that useful if we want to do a GROUP BY for these (as partitioning mean we lose these potentially useful GROUP BY columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dev config from the non-secret configuration file\n",
    "config_dev = configparser.ConfigParser()\n",
    "config_dev.read_file(open('aws_dev.cfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "RAW_I94_MTHLY_SAS7BDAT_DIR = config_dev.get('DATA_PATHS_UDACITY', 'RAW_I94_MTHLY_SAS7BDAT_DIR')\n",
    "\n",
    "PAR_I94_DIR = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_DIR')\n",
    "PAR_I94_DIR_BY_NONE = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_DIR_BY_NONE')\n",
    "PAR_I94_DIR_BY_I94MON = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_DIR_BY_I94MON')\n",
    "PAR_I94_DIR_BY_I94YR_I94MON = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_DIR_BY_I94YR_I94MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective:\n",
      "\n",
      "(1) For each sas7bdat file in this this directory:\n",
      "    /data/18-83510-I94-Data-2016\n",
      "    ... read into a Spark DataFrame, \n",
      "    \n",
      "(2) and immediately write it out into partitioned parquet files to these directory:\n",
      "    (2a) No Partition (for overall stats summary): \n",
      "        par_input_data/i94/i94_parquet/by_none/\n",
      "    (2b) Partitioned by i94mon (for ease if analysis for just the 2016 data): \n",
      "        par_input_data/i94/i94_parquet/by_i94mon/\n",
      "    (2c) Partitioned by i94yr, i94mon (for on-going ETL and analysis. e.g. 2017, 2018, etc.): \n",
      "        par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\\\n",
    "Objective:\n",
    "\n",
    "(1) For each sas7bdat file in this this directory:\n",
    "    {RAW_I94_MTHLY_SAS7BDAT_DIR}\n",
    "    ... read into a Spark DataFrame, \n",
    "    \n",
    "(2) and immediately write it out into partitioned parquet files to these directory:\n",
    "    (2a) No Partition (for overall stats summary): \n",
    "        {PAR_I94_DIR_BY_NONE}\n",
    "    (2b) Partitioned by i94mon (for ease if analysis for just the 2016 data): \n",
    "        {PAR_I94_DIR_BY_I94MON}\n",
    "    (2c) Partitioned by i94yr, i94mon (for on-going ETL and analysis. e.g. 2017, 2018, etc.): \n",
    "        {PAR_I94_DIR_BY_I94YR_I94MON}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxr-xr-x 3 root root 4096 Dec 11 15:34 by_i94mon\n",
      "drwxr-xr-x 3 root root 4096 Dec 11 15:36 by_i94yr_i94mon\n",
      "drwxr-xr-x 2 root root 4096 Dec 11 15:35 by_none\n"
     ]
    }
   ],
   "source": [
    "!ls -l {PAR_I94_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!rm -r {PAR_I94_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir {PAR_I94_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n"
     ]
    }
   ],
   "source": [
    "!ls -l {PAR_I94_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read the 12 monthly SAS7BDAT i94 files from 2016 into a Spark DataFrame. Write the Spark DataFrame into the parquet files in 3 ways:\n",
    "\n",
    "1. no partitioning\n",
    "2. partiion by month\n",
    "3. partition by year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n",
      "Reading (input_path): /data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat\n",
      "Writing (PAR_I94_DIR_BY_NONE): par_input_data/i94/i94_parquet/by_none/\n",
      "Writing (PAR_I94_DIR_BY_I94MON): par_input_data/i94/i94_parquet/by_i94mon/\n",
      "Writing (PAR_I94_DIR_BY_I94YR_I94MON): par_input_data/i94/i94_parquet/by_i94yr_i94mon/\n"
     ]
    }
   ],
   "source": [
    "yy_list = ['16']\n",
    "mmmm_list = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "for yy in yy_list:\n",
    "    for mmm in mmmm_list:\n",
    "        input_dir = f\"{RAW_I94_MTHLY_SAS7BDAT_DIR}\"\n",
    "        input_file = f\"i94_{mmm}{yy}_sub.sas7bdat\"\n",
    "        input_path = f\"{input_dir}/{input_file}\"\n",
    "        \n",
    "        print(f\"Reading (input_path): {input_path}\")\n",
    "        df_spark_i94 = spark.read.format('com.github.saurfang.sas.spark').load(input_path)\n",
    "        \n",
    "        print(f\"Writing (PAR_I94_DIR_BY_NONE): {PAR_I94_DIR_BY_NONE}\")\n",
    "        df_spark_i94.write.mode(\"append\").parquet(PAR_I94_DIR_BY_NONE)\n",
    "        \n",
    "        print(f\"Writing (PAR_I94_DIR_BY_I94MON): {PAR_I94_DIR_BY_I94MON}\")\n",
    "        df_spark_i94.write.mode(\"append\").partitionBy(\"i94mon\").parquet(PAR_I94_DIR_BY_I94MON)\n",
    "        \n",
    "        print(f\"Writing (PAR_I94_DIR_BY_I94YR_I94MON): {PAR_I94_DIR_BY_I94YR_I94MON}\")\n",
    "        df_spark_i94.write.mode(\"append\").partitionBy(\"i94yr\", \"i94mon\").parquet(PAR_I94_DIR_BY_I94YR_I94MON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_i94.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

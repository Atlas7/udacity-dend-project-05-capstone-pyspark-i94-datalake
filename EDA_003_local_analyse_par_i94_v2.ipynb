{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Objective: for the DoubleType columns (in the i94 dataset), get a feel of whether these are actually integer like in nature (i.e. decimal doesn't make much sense), vs float-like in nature (i.e. decimal makes sense)\n",
    "\n",
    "Spoiler alert: it appears all the numeric DoubleType columns in the i94 datasets are integer like in nature. Column `admnum` is `bigint` like, where the rest of the DoubleType columns are `int` like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure Jupyter Notebook display pandas dataframe fully. Show all columns. Do not truncate column value.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dev config from the non-secret configuration file\n",
    "config_dev = configparser.ConfigParser()\n",
    "config_dev.read_file(open('aws_dev.cfg'))\n",
    "\n",
    "PAR_I94_FILE_BY_NONE = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_FILE_BY_NONE')\n",
    "# PAR_I94_FILE_BY_I94MON = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_FILE_BY_I94MON')\n",
    "# PAR_I94_FILE_BY_I94YR_I94MON = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_FILE_BY_I94YR_I94MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94 = spark.read.parquet(PAR_I94_FILE_BY_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Should the `double` column be set as `integer` column?\n",
    "\n",
    "For instance, if the values of a column that is currently auto-parsed in as a `double` type, and that the integer version has the same value, we may conclue that for that column we ought to store that column as an integer column instead of double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cols_with_dtype(df, dtype: str) -> list:\n",
    "    \"\"\" Given a Spark DataFrame and a target data type, return all columns of that data type. \n",
    "    Example Usage: get_cols_with_dtype(df_i94, 'double')\n",
    "    \"\"\"\n",
    "    double_col_list = [item[0] for item in df.dtypes if item[1].startswith(f\"{dtype}\")]\n",
    "    return double_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get_cols_with_dtype(df_i94, 'double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def should_be_int(df, colname: str) -> bool:\n",
    "    \"\"\" Check entire Spark DataFrame Column. If integer form has same as the float form, return True \n",
    "    Example Usage: should_be_int(df_i94, 'cicid')\n",
    "    \"\"\"\n",
    "    df.createOrReplaceTempView(\"_tmp_df\")\n",
    "\n",
    "    sql_str = f\"\"\"\\\n",
    "        select count({colname}) as records\n",
    "        from _tmp_df\n",
    "        where ({colname} is not null) and (abs({colname} - bigint({colname}))) > 0\n",
    "    \"\"\"  \n",
    "    \n",
    "    # run spark SQL\n",
    "    #print(sql_str)\n",
    "    _tmp_df = spark.sql(sql_str)\n",
    "\n",
    "    # Grab the value of `records`    \n",
    "    diff_records = _tmp_df.head()[0]\n",
    "\n",
    "    return diff_records == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# should_be_int(df_i94, 'cicid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def which_int_type(df, colname: str) -> str:\n",
    "    \"\"\" Check entire Spark DataFrame Column. Should the int column be of IntegerType (int) or LongType (bigint)? \n",
    "    https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "        ByteType: Represents 1-byte signed integer numbers. The range of numbers is from -128 to 127.\n",
    "        ShortType: Represents 2-byte signed integer numbers. The range of numbers is from -32768 to 32767.\n",
    "        IntegerType: Represents 4-byte signed integer numbers. The range of numbers is from -2147483648 to 2147483647.\n",
    "        LongType: Represents 8-byte signed integer numbers. The range of numbers is from -9223372036854775808 to 9223372036854775807.        \n",
    "    \"\"\"\n",
    "    \n",
    "    df.createOrReplaceTempView(\"_tmp_df\")\n",
    "     \n",
    "    sql_str = f\"\"\"\\\n",
    "        select\n",
    "            case\n",
    "                when max(abs({colname})) <  2147483647 then 'IntegerType'\n",
    "                else 'LongType'\n",
    "            end as proposed\n",
    "        from _tmp_df\n",
    "        where {colname} is not null\n",
    "    \"\"\"  \n",
    "    \n",
    "    # run spark SQL\n",
    "    #print(sql_str)\n",
    "    _tmp_df = spark.sql(sql_str)\n",
    "\n",
    "    # Grab the value of `proposed`\n",
    "    proposed = _tmp_df.head()[0]\n",
    "    \n",
    "    return proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# which_int_type(df_i94, 'cicid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# which_int_type(df_i94, 'admnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def optimise_double(df):\n",
    "    double_list = get_cols_with_dtype(df, 'double')\n",
    "    #print(double_list)\n",
    "    return [{\n",
    "        \"column_name\": colname,\n",
    "        \"proposed\": which_int_type(df, colname) if should_be_int(df, colname) else 'double'\n",
    "    } for idx, colname in enumerate(double_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_name': 'cicid', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94yr', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94mon', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94cit', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94res', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'arrdate', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94mode', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'depdate', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94bir', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'i94visa', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'count', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'biryear', 'proposed': 'IntegerType'},\n",
       " {'column_name': 'admnum', 'proposed': 'LongType'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimise_double(df_i94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Mini insights:\n",
    "\n",
    "* These numeric columns currently are auto-parsed as DoubleType.\n",
    "* This notebook aims to understand nature of these columns - conceptually are they integer like - e.g. IntegerType (int) and LongType (bigint).\n",
    "* This notebook is purely exploratory. It appears the DoubleType store numeric values covering largest range and might be safest. It is possible that we keep these numeric columns as double. It is important to get an appreciate of the integer-like nature of the numeric columns though (eg. year 2016 makes more sense than year 2016.0; likewise, month 3 makes more sense than month 3.0, and so on).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

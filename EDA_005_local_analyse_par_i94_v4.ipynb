{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Objective: test translate the SAS Date columns into Python datetimes. There are two SAS columns:\n",
    "\n",
    "* `arrdate`: no `null` from EDA.\n",
    "* `depdate`: from EDA we observed records with `null`\n",
    "\n",
    "More insights:\n",
    "\n",
    "* it appears that the monthly datasets are mutually exclusive to each other. This means that the same CICID (say, 5748517) does not neccessary represent the same immigrant in Jan dataset, vs the Feb dataset (and so on). i.e it appears that CICID is just a way for the dataset to capture immigration data.\n",
    "* It also appears that the i94yr and i94mon corresponds to the arrivate date (into the US) - looking at an example. (we can validate this by comparing the year-month of the dataset, vs the year-month of the arrival date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure Jupyter Notebook display pandas dataframe fully. Show all columns. Do not truncate column value.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "# Dev config from the non-secret configuration file\n",
    "config_dev = configparser.ConfigParser()\n",
    "config_dev.read_file(open('aws_dev.cfg'))\n",
    "\n",
    "PAR_I94_FILE_BY_NONE = config_dev.get('DATA_PATHS_LOCAL', 'PAR_I94_FILE_BY_NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94 = spark.read.parquet(PAR_I94_FILE_BY_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_datetime(sas_date):\n",
    "    try:\n",
    "        if (sas_date == 'null'):\n",
    "            sas_date = 0\n",
    "        start_cutoff = datetime(1960, 1, 1)\n",
    "        return start_cutoff + timedelta(days=int(sas_date))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "udf_datetime_from_sas = F.udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94 = df_i94.withColumn('arrdate_pydt', udf_datetime_from_sas(df_i94.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94 = df_i94.withColumn('depdate_pydt', udf_datetime_from_sas(df_i94.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- arrdate_pydt: date (nullable = true)\n",
      " |-- depdate_pydt: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "Hypothesis: the same CICID of different monthly i94 datasets are mutually exclusive.\n",
    "\n",
    "Observation: it appears that the monthly datasets are mutually exclusive to each other. This means that the same CICID (say, 5748517) does not neccessary represent the same immigrant in Jan dataset, vs the Feb dataset (and so on). i.e it appears that CICID is just a way for the dataset to capture immigration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+------------+-------+------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|arrdate_pydt|depdate|depdate_pydt|\n",
      "+---------+------+------+------+------+-------+-------+------------+-------+------------+\n",
      "|5748517.0|2016.0|   1.0| 135.0| 135.0|    LOS|20484.0|  2016-01-31|   null|        null|\n",
      "|5748517.0|2016.0|   3.0| 135.0| 135.0|    NYC|20541.0|  2016-03-28|20545.0|  2016-04-01|\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|  2016-04-30|20582.0|  2016-05-08|\n",
      "|5748517.0|2016.0|   6.0| 252.0| 209.0|    AGA|20631.0|  2016-06-26|   null|        null|\n",
      "|5748517.0|2016.0|   7.0| 251.0| 251.0|    NYC|20659.0|  2016-07-24|20665.0|  2016-07-30|\n",
      "|5748517.0|2016.0|   8.0| 117.0| 117.0|    WAS|20691.0|  2016-08-25|20699.0|  2016-09-02|\n",
      "|5748517.0|2016.0|   9.0| 254.0| 276.0|    AGA|20723.0|  2016-09-26|20728.0|  2016-10-01|\n",
      "|5748517.0|2016.0|  10.0| 111.0| 111.0|    NYC|20755.0|  2016-10-28|20762.0|  2016-11-04|\n",
      "|5748517.0|2016.0|  11.0| 268.0| 268.0|    LOS|20788.0|  2016-11-30|20789.0|  2016-12-01|\n",
      "+---------+------+------+------+------+-------+-------+------------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94.createOrReplaceTempView(\"df_i94\")\n",
    "\n",
    "df_i94_agg_1 = spark.sql(\"\"\"\n",
    "select\n",
    "    cicid,\n",
    "    i94yr,\n",
    "    i94mon,\n",
    "    i94cit,\n",
    "    i94res,\n",
    "    i94port,\n",
    "    arrdate,\n",
    "    arrdate_pydt,\n",
    "    depdate,\n",
    "    depdate_pydt\n",
    "from df_i94\n",
    "where cicid = 5748517\n",
    "order by 1,2,3\n",
    "limit 1000\n",
    "\"\"\")\n",
    "\n",
    "df_i94_agg_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Hypothesis 2\n",
    "\n",
    "Hypothesis: the year-month of the i94 form (`i94yr` and `i94mon`) matches exactly as the arrivate date into the US (`year(arrdate_pydt)` and `month(arrdate_pydt)`)\n",
    "\n",
    "Observation: It also appears that the i94yr and i94mon corresponds to the arrivate date (into the US) - looking at an example. (we can validate this by comparing the year-month of the dataset, vs the year-month of the arrival date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+--------+\n",
      "| i94yr|i94mon|arr_year|arr_mon|count(1)|\n",
      "+------+------+--------+-------+--------+\n",
      "|2016.0|   1.0|    2016|      1| 2847924|\n",
      "|2016.0|   2.0|    2016|      2| 2570543|\n",
      "|2016.0|   3.0|    2016|      3| 3157072|\n",
      "|2016.0|   4.0|    2016|      4| 3096313|\n",
      "|2016.0|   5.0|    2016|      5| 3444249|\n",
      "|2016.0|   6.0|    2016|      6| 3574989|\n",
      "|2016.0|   7.0|    2016|      7| 4265031|\n",
      "|2016.0|   8.0|    2016|      8| 4103570|\n",
      "|2016.0|   9.0|    2016|      9| 3733786|\n",
      "|2016.0|  10.0|    2016|     10| 3649136|\n",
      "|2016.0|  11.0|    2016|     11| 2914926|\n",
      "|2016.0|  12.0|    2016|     12| 3432990|\n",
      "+------+------+--------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_agg_2 = spark.sql(\"\"\"\n",
    "select\n",
    "    i94yr,\n",
    "    i94mon,\n",
    "    year(arrdate_pydt) as arr_year,\n",
    "    month(arrdate_pydt) as arr_mon,\n",
    "    count(*)\n",
    "from df_i94\n",
    "group by 1,2,3,4\n",
    "order by 1,2,3,4\n",
    "\"\"\")\n",
    "\n",
    "df_i94_agg_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
